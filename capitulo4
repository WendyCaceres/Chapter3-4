# CAPÍTULO 4: DISEÑO DE UN LIMITADOR

En un sistema de red, un limitador de tasa se utiliza para controlar la tasa de tráfico enviado por un cliente o un servicio. En el mundo HTTP, un limitador de tasa limita el número de solicitudes de clientes que se pueden enviar durante un periodo determinado. Si el número de API supera el umbral definido por el limitador de velocidad, todas las
exceso de llamadas se bloquean. He aquí algunos ejemplos:

- Un usuario no puede escribir más de 2 posts por segundo.
  
- Puede crear un máximo de 10 cuentas al día desde la misma dirección IP.
  
- No se pueden reclamar recompensas más de 5 veces por semana desde el mismo dispositivo.
mismo dispositivo.

En este capítulo, se le pide que diseñe un limitador de velocidad. Antes de comenzar el diseño, primero veremos los beneficios de usar un limitador de tasa API:

- Prevenir la inanición de recursos causada por ataques de Denegación de Servicio (DoS) [1]. Casi todas las API publicadas por grandes empresas tecnológicas aplican algún tipo de limitación de velocidad. Por ejemplo, Twitter limita el número de tweets a 300 cada 3
horas [2]. Las API de Google Docs tienen el siguiente límite por defecto: 300 por usuario
por 60 segundos para solicitudes de lectura [3]. Un limitador de velocidad evita los ataques ya sean intencionados o no, bloqueando el exceso de llamadas.

- Reducción de costes. Limitar el exceso de peticiones significa menos servidores y asignar más recursos a las API de alta prioridad. La limitación de la tasa es extremadamente importante para las empresas que utilizan API de terceros de pago. Por ejemplo, se cobra por llamada para las siguientes API externas: comprobar el crédito, realizar un pago, recuperar historiales médicos, etc.Limitar el número de llamadas es
esencial para reducir costes.

- Evitar la sobrecarga de los servidores. Para reducir la carga de los servidores
para filtrar el exceso de peticiones causadas por bots o el mal comportamiento de los
de los usuarios.

# Paso 1 - Comprender el problema y establecer alcance del diseño

El limitador de velocidad puede implementarse utilizando diferentes algoritmos, cada uno con sus pros y contras. Las interacciones entre un entrevistador y un candidato
ayudan a aclarar el tipo de limitador de velocidad que queremos construir.

Candidato: ¿Qué tipo de limitador de velocidad vamos a diseñar? ¿Es un limitador de velocidad del lado del cliente o del lado del servidor?

Entrevistador: Buena pregunta. Nos centraremos en el limitador de velocidad de la API del servidor.

Candidato: ¿El limitador de velocidad estrangula las solicitudes de API basándose en la IP, el ID de usuario u otras propiedades?

Entrevistador: El limitador de velocidad debe ser lo suficientemente flexible para admitir diferentes conjuntos de reglas de limitación.

Candidato: ¿Cuál es la escala del sistema? ¿Está pensado para una nueva empresa o para una empresa con una gran base de usuarios?

Entrevistador: El sistema debe ser capaz de gestionar un gran número de solicitudes.

Candidato: ¿Funcionará el sistema en un entorno distribuido?

Entrevistador: Sí.

Candidato: ¿El limitador de velocidad es un servicio independiente o debe implementarse
en el código de la aplicación?

Entrevistador: Es una decisión de diseño que depende de ti.

Candidato: ¿Tenemos que informar a los usuarios que están limitados?

Entrevistador: Sí.

Requisitos

He aquí un resumen de los requisitos del sistema:

- Limitar con precisión las peticiones excesivas.
  
- Baja latencia. El limitador de velocidad no debe ralentizar el tiempo de respuesta HTTP.
  
- Utilizar la menor cantidad de memoria posible.
  
- Limitación de velocidad distribuida. El limitador de velocidad puede compartirse entre varios servidores o procesos.
  
- Manejo de excepciones. Mostrar excepciones claras a los usuarios cuando sus solicitudes
están estrangulados.

- Alta tolerancia a fallos. Si hay algún problema con el limitador de velocidad (por
ejemplo, un servidor de caché se desconecta), no afecta a todo el sistema.

# Paso 2 - Proponer un diseño de alto nivel y conseguir apoyo
Mantengamos las cosas sencillas y utilicemos un modelo básico de cliente y servidor para la comunicación.

# ¿Dónde colocar el limitador de velocidad?

Intuitivamente, se puede implementar un limitador de velocidad en el cliente o en el servidor.

- Implementación del lado del cliente. En general, el cliente es un lugar poco fiable para imponer la limitación de velocidad porque las peticiones del cliente pueden ser falsificadas por actores maliciosos. Además, es posible que no tengamos control sobre la implementación del cliente.
  
- Implementación del lado del servidor. La Figura 4-1 muestra un limitador de velocidad que se coloca en el lado del servidor.
  
(Imagen) Una imagen que contiene la descripción del reloj generada automáticamente

Además de las implementaciones del lado del cliente y del lado del servidor, existe una alternativa. En lugar de colocar un limitador de velocidad en los servidores API, creamos un middleware limitador, que regula las peticiones a sus API, como se muestra en la Figura 4-2.

(Captura) Captura de pantalla de un teléfono móvil Descripción generada automáticamente

Utilicemos un ejemplo de la Figura 4-3 para ilustrar cómo funciona la limitación de velocidad en este diseño. Supongamos que nuestra API permite 2 solicitudes por segundo, y un cliente envía 3 peticiones al servidor en un segundo. Las dos primeras
enrutadas a los servidores API. Sin embargo, el middleware limitador de velocidad estrangula la tercera solicitud y devuelve un código de estado HTTP 429. La respuesta HTTP 429 indica que el usuario ha enviado demasiadas solicitudes.

(Captura) Captura de pantalla de un teléfono móvil Descripción generada automáticamente

Los microservicios en la nube [4] se han hecho muy populares y la limitación de la tasa se suele implementarse en un componente llamado pasarela API. La pasarela API
es un servicio totalmente gestionado que soporta limitación de tasa, terminación SSL
autenticación, listas blancas de IP, servicio de contenido estático, etc. Por ahora, sólo necesitamos saber que la pasarela API es un middleware que admite la limitación de velocidad.

Al diseñar un limitador de velocidad, una pregunta importante que debemos hacernos es:
¿dónde debe implementarse el limitador de velocidad, en el servidor o en una pasarela?
No hay una respuesta absoluta. Depende de la pila tecnológica de recursos de ingeniería, prioridades, objetivos, etc. Aquí mostraremos algunas directrices generales:

- Evalúe su pila tecnológica actual, como lenguaje de programación,
servicio de caché, etc. Asegúrese de que su lenguaje de programación actual es
eficiente para implementar la limitación de velocidad en el lado del servidor.

-Identifique el algoritmo de limitación de velocidad que se ajuste a las necesidades de su empresa. Cuando implementas todo en el lado del servidor, tiene el control total del algoritmo. Sin embargo, su elección puede verse limitada si utiliza una pasarela de terceros.

- Si ya ha utilizado una arquitectura de microservicios y ha incluido una pasarela de API en el diseño para realizar la autenticación, listas blancas de IP, etc., puede añadir un limitador de velocidad a la pasarela de API.

- Construir su propio servicio de limitación de velocidad lleva tiempo. Si no dispone de
recursos de ingeniería suficientes para implementar un limitador de velocidad, una pasarela de API comercial es una mejor opción.

# Algoritmos de limitación de velocidad

La limitación de velocidad puede implementarse utilizando diferentes algoritmos, y cada uno de ellos tiene sus pros y sus contras. Aunque este capítulo no se centra en
algoritmos, entenderlos a alto nivel ayuda a elegir el algoritmo o combinación de algoritmos que se ajuste a nuestros casos de uso. He aquí una lista de
algoritmos populares:

- Token bucket
  
- Cubo de fugas
  
- Contador de ventana fija

- Registro de ventanas deslizantes
  
- Contador de ventana móvil
  
# Algoritmo Token Bucket

El algoritmo token bucket es muy utilizado para limitar la velocidad. Es sencillo,
bien entendido y comúnmente utilizado por las empresas de Internet. Tanto Amazon
[5] y Stripe [6] utilizan este algoritmo para limitar sus peticiones API.

El algoritmo de token bucket funciona de la siguiente manera:

- Un token bucket es un contenedor que tiene una capacidad predefinida. Los tokens se
en el cubo a un ritmo preestablecido periódicamente. Una vez que el cubo está lleno, no se añaden más fichas. Como se muestra en la Figura 4-4, la capacidad del cubo es de 4 fichas.El rellenador pone 2 fichas en el cubo cada segundo. Una vez que el cubo esté lleno, las fichas adicionales rebosarán.

(Imagen)Un cuadro que contiene el juego, la tabla Descripción generada automáticamente

- Cada solicitud consume una ficha. Cuando llega una solicitud, se comprueba si
hay suficientes fichas en el cubo. La figura 4-5 explica cómo funciona.

- Si hay suficientes fichas, sacamos una ficha por cada solicitud y hacemos pasar la solicitud.

- Si no hay suficientes fichas, la solicitud se descarta.

(Mapa)Detalle de un mapa Descripción generada automáticamente

La Figura 4-6 ilustra cómo funcionan el consumo de fichas, la recarga y la lógica de limitación de velocidad. En este ejemplo, el tamaño del cubo de fichas es 4, y la tasa de recarga es de 4 por 1 minuto.

(Imagen)Primer plano de un texto sobre fondo blanco Descripción generada automáticamente

El algoritmo del cubo de fichas toma dos parámetros:

- Tamaño del cubo: número máximo de fichas que puede contener el cubo.
  
- Tasa de relleno: número de fichas que se introducen en el cubo cada segundo.
  
¿Cuántos cubos necesitamos? Esto varía y depende de las reglas de limitación de la tasa. He aquí algunos ejemplos.

- Suele ser necesario tener distintos buckets para distintos puntos finales de API. Por ejemplo, si a un usuario se le permite hacer 1 publicación por segundo, añadir
150 amigos por día, y como 5 mensajes por segundo, 3 cubos son necesarios para
cada usuario.

-Si tenemos que limitar las solicitudes en función de las direcciones IP, cada dirección IP requiere un cubo.

- Si el sistema permite un máximo de 10.000 peticiones por segundo, tiene sentido tener un cubo global compartido por todas las peticiones.
  
Ventajas:

- El algoritmo es fácil de implementar.
  
- Uso eficiente de la memoria.
  
- El cubo de peticiones permite una ráfaga de tráfico durante periodos cortos. Una petición puede pasar mientras queden tokens.
  
Contras:

- Dos parámetros del algoritmo son el tamaño del cubo y la tasa de rellenado de tokens.
Sin embargo, puede resultar difícil ajustarlos correctamente.

# Algoritmo de cubo con fugas

El algoritmo de cubo con fugas es similar al de cubo de tokens, excepto en que las peticiones se procesan a un ritmo fijo. Suele implementarse con una cola FIFO (primero en entrar, primero en salir). El algoritmo funciona de la siguiente manera: 

- Cuando llega una solicitud, el sistema comprueba si la cola está llena. Si no está
llena, la solicitud se añade a la cola.

- En caso contrario, se descarta.
  
- Las solicitudes se sacan de la cola y se procesan a intervalos regulares.
  
La figura 4-7 explica el funcionamiento del algoritmo.

(Mapa)Primer plano de un mapa Descripción generada automáticamente

El algoritmo Leaking Bucket toma los dos parámetros siguientes:

- Tamaño del cubo: es igual al tamaño de la cola. La cola contiene las solicitudes que
procesar a un ritmo fijo.

- Tasa de salida: define cuántas solicitudes pueden procesarse a una tasa fija, normalmente en segundos.

Shopify, una empresa de comercio electrónico, utiliza leaky buckets para limitar la tasa [7].

Ventajas:

- Eficiencia de memoria dado el tamaño limitado de la cola.
  
- Las solicitudes se procesan a un ritmo fijo, por lo que es adecuado para casos de uso
en los que se necesita una tasa de salida estable.

Contras:

- Una ráfaga de tráfico llena la cola de solicitudes antiguas y, si no se procesan a tiempo, las solicitudes recientes se verán afectadas por una limitación.
  
- Hay dos parámetros en el algoritmo. Puede que no sea fácil sintonizar ellos adecuadamente.

# Algoritmo de contador de ventana fija

El algoritmo de contador de ventana fija funciona de la siguiente manera:

- El algoritmo divide la línea de tiempo en ventanas de tiempo de tamaño fijo y asigna
un contador para cada ventana.

- Cada solicitud incrementa el contador en uno.
  
- Una vez que el contador alcanza el umbral predefinido, se descartan nuevas peticiones hasta que se inicia una nueva ventana temporal.

Utilicemos un ejemplo concreto para ver cómo funciona. En la Figura 4-8, la unidad
es de 1 segundo y el sistema permite un máximo de 3 peticiones por segundo. En cada ventana de segundos, si se reciben más de 3 peticiones, se descartan las peticiones adicionales, como se muestra en la figura 4-8.

(Captura)Captura de pantalla de un móvil Descripción generada automáticamente

Un problema importante de este algoritmo es que una ráfaga de tráfico en los bordes de
ventanas de tiempo podría hacer que pasasen más peticiones de la cuota permitida.
Considere el siguiente caso:

(Captura)Captura de pantalla de una publicación en redes sociales Descripción generada automáticamente.

En la Figura 4-9, el sistema permite un máximo de 5 peticiones por minuto, y
la cuota disponible se restablece en el minuto redondo para humanos. Como se ve
hay cinco solicitudes entre las 2:00:00 y las 2:01:00 y cinco solicitudes más
entre las 2:01:00 y las 2:02:00. En la ventana de un minuto entre las 2:00:30
y las 2:01:30, pasan 10 peticiones. Es decir, el doble de las permitidas.

Ventajas:

- Memoria eficiente.
  
- Fácil de entender.
  
- El restablecimiento de la cuota disponible al final de una ventana de tiempo unitaria se ajusta a ciertos casos de uso.

Contras:

- Los picos de tráfico en los extremos de una ventana pueden hacer que pasen más peticiones que la cuota permitida.
  
# Algoritmo de registro de ventana deslizante
Como se ha comentado anteriormente, el algoritmo de contador de ventana fija tiene un problema importante: permite que pasen más solicitudes en los bordes de una ventana. El algoritmo soluciona el problema. Funciona de la siguiente manera:

- El algoritmo registra las marcas de tiempo de las solicitudes. Las marcas de tiempo
normalmente se guardan en una caché, como los conjuntos ordenados de Redis [8].

- Cuando llega una nueva petición, elimina todas las marcas de tiempo desactualizadas.
Las marcas de tiempo obsoletas se definen como aquellas más antiguas que el inicio de la ventana de tiempo actual.

- Añada la marca de tiempo de la nueva solicitud al registro.
  
- Si el tamaño del registro es igual o inferior al recuento permitido, se acepta la solicitud. En caso contrario, se rechaza.
  
Explicamos el algoritmo con un ejemplo, como se muestra en la Figura 4-10.

(Imagen)Un primer plano de texto sobre fondo blanco Descripción automáticamente
generado automáticamente.

En este ejemplo, el limitador de velocidad permite 2 solicitudes por minuto. Normalmente,
Las marcas de tiempo de Linux se almacenan en el registro.Sin embargo, en nuestro ejemplo se utiliza una representación del tiempo legible para el ser humano para una mejor legibilidad.

- El registro está vacío cuando llega una nueva petición a la 1:00:01. Por lo tanto, la solicitud está permitida.
  
- Cuando llega una nueva solicitud a las 1:00:30, se inserta la marca de tiempo 1:00:30 en el registro. Después de la inserción, el tamaño del registro es 2, no mayor que el recuento permitido.Por lo tanto, la solicitud está permitida.
  
- Una nueva solicitud llega a las 1:00:50, y la marca de tiempo se inserta en el registro.Tras la inserción, el tamaño del registro es 3, mayor que el tamaño 2 permitido.
Por lo tanto, esta solicitud se rechaza aunque la marca de tiempo permanece en el registro.

- A la 1:01:40 llega una nueva solicitud. Las solicitudes en el intervalo [1:00:40,1:01:40) están dentro del intervalo de tiempo más reciente, pero las solicitudes enviadas antes de la 1:00:40 están obsoletas. Dos marcas de tiempo obsoletas, 1:00:01 y 1:00:30, se eliminan del registro.Tras la operación de eliminación, el tamaño del registro pasa a ser 2; por lo tanto la solicitud es aceptada.

Ventajas:

- La limitación de velocidad implementada por este algoritmo es muy precisa. En cualquier
ventana móvil, las solicitudes no superarán el límite de velocidad.

Contras:

- El algoritmo consume mucha memoria porque, aunque se rechace una solicitud, su marca de tiempo puede seguir almacenada en la memoria.
  
# Algoritmo de contador de ventana deslizante

El algoritmo de contador de ventana deslizante es un enfoque híbrido que combina
el contador de ventana fija y el registro de ventana deslizante. El algoritmo puede
implementado mediante dos enfoques diferentes. Explicamos uno
implementación en esta sección y proporcionar referencia para el resto
al final de la sección. La Figura 4-11 ilustra cómo funciona este
algoritmo.

(Imagen)Una imagen que contiene la descripción del reloj generada automáticamente

Supongamos que el limitador de velocidad permite un máximo de 7 peticiones por minuto, y
hay 5 peticiones en el minuto anterior y 3 en el minuto actual. Para
una nueva solicitud que llega en una posición del 30% en el minuto actual, el
número de solicitudes en la ventana móvil se calcula mediante la siguiente fórmula:

- Peticiones en la ventana actual + peticiones en la ventana anterior * solapamiento
porcentaje de la ventana rodante y la ventana anterior

- Utilizando esta fórmula, obtenemos 3 + 5 * 0,7% = 6,5 solicitudes. Dependiendo del
caso de uso, el número puede redondearse hacia arriba o hacia abajo. En nuestro ejemplo
se redondea a 6.

Dado que el limitador de velocidad permite un máximo de 7 solicitudes por minuto, la solicitud actual puede pasar. Sin embargo, el límite se alcanzará tras
de recibir una petición más.

Debido a la limitación de espacio, no discutiremos la otra implementación
aquí. Los lectores interesados pueden consultar el material de referencia [9]. Este
algoritmo no es perfecto. Tiene pros y contras.

Pros

- Suaviza los picos de tráfico porque la tasa se basa en la tasa media de la ventana anterior.

- Uso eficiente de la memoria.
  
Contras

- Sólo funciona para una ventana retrospectiva no tan estricta. Es una aproximación de
la tasa real porque asume que las peticiones en la ventana anterior están
distribuidas uniformemente. Sin embargo, este problema puede no ser tan grave como parece. Según los experimentos realizados por Cloudflare [10], sólo el 0,003% de
las solicitudes se permiten incorrectamente o tienen una tasa limitada entre 400 millones de solicitudes.

# Arquitectura de alto nivel

La idea básica de los algoritmos de limitación de tasa es simple. A alto nivel, necesitamos un contador para llevar la cuenta de cuántas solicitudes se envían desde el mismo usuario, dirección IP, etc. Si el contador es mayor que el límite, la solicitud se rechaza.

¿Dónde almacenamos los contadores? Utilizar la base de datos no es una buena idea debido a lentitud de acceso al disco. Se elige la caché en memoria porque es rápida y
soporta una estrategia de expiración basada en el tiempo. Por ejemplo, Redis [11] es una
es una opción popular para implementar la limitación de velocidad. Es un almacén en memoria que ofrece dos comandos: INCR y EXPIRE.

- INCR: Incrementa el contador almacenado en 1.
  
- EXPIRE: Establece un tiempo de espera para el contador. Si el tiempo de espera expira, el contador se borra automáticamente.

La Figura 4-12 muestra la arquitectura de alto nivel para la limitación de velocidad, y ésta funciona de la siguiente manera:

(Mapa)Un primer plano de un mapa Descripción generada automáticamente

- El cliente envía una solicitud al middleware de limitación de velocidad.
  
- El cliente envía una solicitud al middleware de limitación de velocidad.
correspondiente en Redis y comprueba si se ha alcanzado el límite o no.

- Si se alcanza el límite, se rechaza la solicitud.
  
- Si no se alcanza el límite, la solicitud se envía a los servidores API. Mientras tanto,
el sistema incrementa el contador y lo guarda de nuevo en Redis.

# Paso 3 - Diseño en profundidad

El diseño de alto nivel de la Figura 4-12 no responde a las siguientes
preguntas:

- ¿Cómo se crean las reglas de limitación de velocidad? ¿Dónde se almacenan las reglas?
  
- ¿Cómo se gestionan las peticiones con limitación de velocidad?
  
En esta sección, primero responderemos a las preguntas relativas a las reglas de limitación de velocidad y, a continuación, repasaremos las estrategias para gestionar las solicitudes con limitación de velocidad. Por último, discutiremos la limitación de velocidad en entornos distribuidos, un diseño detallado,
optimización del rendimiento y supervisión.

# Reglas de limitación de tarifas

Lyft ha abierto su componente de limitación de velocidad [12]. Nos adentraremos en
del componente y veremos algunos ejemplos de reglas de limitación de velocidad:

dominio: mensajería

descriptores:

  -clave: tipo_mensaje
   
 valor: marketing
 
 límite_de_tarifa:
 
 unidad: día
 
 peticiones_por_unidad 5
 
En el ejemplo anterior, el sistema está configurado para permitir un máximo de 5
mensajes de marketing al día. He aquí otro ejemplo:

dominio: auth

descriptores:

   -clave: auth_type
   
 valor: login
 
 rate_limit:
 
 unidad: minuto
 
 peticiones_por_unidad: 5
 
Esta regla indica que los clientes no pueden iniciar sesión más de 5 veces en 1
minuto. Las reglas se escriben generalmente en archivos de configuración y se guardan en el  disco.
# Superación del límite de velocidad
En caso de que una solicitud tenga un límite de velocidad, las API devuelven al cliente un código de respuesta HTTP 429 (demasiadas solicitudes) al cliente. Dependiendo de los casos de uso, podemos poner en cola las solicitudes de velocidad limitada para procesarlas más tarde. Por ejemplo, si algunos pedidos están limitados por sobrecarga del sistema, podemos pedir para procesarlos más tarde.

# Cabeceras del limitador de velocidad

¿Cómo sabe un cliente si está siendo limitado? ¿Y cómo sabe
el número de solicitudes restantes permitidas antes de ser
antes de ser estrangulado? La respuesta está en las cabeceras de respuesta HTTP. El limitador de velocidad devuelve las siguientes cabeceras HTTP a los clientes:

X-Ratelimit-Remaining: El número restante de peticiones permitidas dentro de
la ventana.

X-Ratelimit-Limit: Indica cuántas llamadas puede hacer el cliente por ventana de
ventana.

X-Ratelimit-Retry-After: El número de segundos que hay que esperar hasta poder
volver a realizar una petición sin ser estrangulado.

Cuando un usuario ha enviado demasiadas peticiones, aparece un error 429 too many requests y X-Ratelimit-Retry-After.

# Diseño detallado

La Figura 4-13 presenta un diseño detallado del sistema.

(Mapa)Detalle de un mapa Descripción generada automáticamente

- Las reglas se almacenan en el disco. Los trabajadores extraen con frecuencia reglas del disco y las almacenan en la caché.
  
- Cuando un cliente envía una solicitud al servidor, ésta se envía primero al middleware limitador de velocidad.

- El middleware limitador de velocidad carga las reglas de la caché. Obtiene contadores y
última solicitud de la caché de Redis. Basándose en la respuesta, el
decide:

- Si la solicitud no tiene limitación de velocidad, se reenvía a los servidores API.

- Si la solicitud está limitada en cuanto a velocidad, el limitador de velocidad devuelve al cliente el error 429 too many requests al cliente. Mientras tanto, la solicitud se descarta o se reenvía a la cola.

# Limitador de velocidad en un entorno distribuido

Construir un limitador de velocidad que funcione en un entorno de un solo servidor no es
difícil. Sin embargo, escalar el sistema para que admita varios servidores y
servidores y subprocesos simultáneos es otra historia. Existen dos retos:

- Condición de carrera
  
- Problemas de sincronización
  
# Condición de carrera

Como se discutió anteriormente, el limitador de velocidad funciona de la siguiente manera en el alto nivel:

- Lee el valor del contador de Redis.
  
- Comprueba si (contador + 1) supera el umbral.
  
- Si no, incrementa el valor del contador en 1 en Redis.
  
Las condiciones de carrera pueden ocurrir en un entorno altamente concurrente como se muestra en la Figura 4-14.

(Imagen)Una imagen que contiene la captura de pantalla Descripción generada automáticamente.

Supongamos que el valor del contador en Redis es 3. Si dos peticiones concurrentes leen
el valor del contador antes de que cualquiera de ellas escriba el valor de vuelta, cada una incrementará el contador en uno y lo escribirá de nuevo sin comprobar el otro hilo.
Ambas peticiones (hilos) creen que tienen el valor correcto del contador 4. Sin embargo, el valor correcto del contador debería ser 5.

Los bloqueos son la solución más obvia para resolver la condición de carrera. Sin embargo
los bloqueos ralentizarán significativamente el sistema. Dos estrategias son
comúnmente utilizadas para resolver el problema: el script Lua [13] y la estructura de datos ordenados en Redis [8]. Los lectores interesados en estas estrategias pueden consultar los materiales de referencia correspondientes [8] [13].

# Problema de sincronización

La sincronización es otro factor importante a tener en cuenta en un entorno distribuido. Para dar soporte a millones de usuarios, un servidor limitador de velocidad podría no ser suficiente para gestionar el tráfico. Cuando se utilizan varios servidores limitadores de velocidad es necesaria la sincronización. Por ejemplo, en la parte izquierda de la Figura 4-15 el cliente 1 envía peticiones al limitador de velocidad 1, y el cliente 2 envía peticiones al limitador de velocidad 2. Como la capa web no tiene estado, los clientes pueden enviar solicitudes a un limitador de velocidad diferente, como se muestra a la derecha de la Figura 4-15. Si no hay sincronización, el limitador de velocidad 1 no contiene ningún dato sobre el cliente 2. Por lo tanto, el
limitador de velocidad no puede funcionar correctamente.

(Imagen)Una imagen que contiene texto, mapa Descripción generada automáticamente.

Una posible solución es utilizar sesiones pegajosas que permitan a un cliente enviar
tráfico al mismo limitador de velocidad. Esta solución no es aconsejable porque no es
escalable ni flexible. Un enfoque mejor es utilizar almacenes de datos
centralizados como Redis. El diseño se muestra en la Figura 4-16.

(Mapa)Primer plano de un mapa Descripción generada automáticamente

# Optimización del rendimiento

La optimización del rendimiento es un tema común en las entrevistas de diseño de sistemas. Cubriremos dos áreas a mejorar.

En primer lugar, la configuración de varios centros de datos es crucial para un limitador de velocidad porque la latencia es alta para los usuarios situados lejos del centro de datos. La mayoría de los proveedores de servicios en la nube construyen muchas ubicaciones de servidores de borde en todo el mundo. Por ejemplo,
desde el 20/5-2020, Cloudflare tiene 194 servidores de borde distribuidos geográficamente
[14]. El tráfico se enruta automáticamente al servidor de borde más cercano para reducir
latencia.

(Plano)Un primer plano de un logotipo Descripción generada automáticamente

En segundo lugar, sincronice los datos con un modelo de consistencia eventual. Si no
modelo de consistencia eventual, consulte la sección "Consistencia" del
en el "Capítulo 6: Diseño de un almacén de claves y valores".

# Supervisión

Una vez instalado el limitador de velocidad, es importante recopilar datos analíticos
para comprobar si el limitador de velocidad es eficaz. Principalmente, queremos 
asegurarnos de que:

- El algoritmo de limitación de velocidad es eficaz.
  
- Las reglas de limitación de velocidad son efectivas.
  
Por ejemplo, si las reglas de limitación de tarifas son demasiado estrictas, muchas solicitudes válidas abandonó. En este caso, queremos relajar un poco las reglas. En otro
ejemplo, nos damos cuenta de que nuestro limitador de velocidad se vuelve ineficaz cuando se produce un aumento repentino del tráfico, como en el caso de las ventas flash. En este caso, podemos sustituir el algoritmo para soportar el tráfico de ráfagas. Token bucket es una buena opción en este caso.

# Paso 4 - Conclusión

En este capítulo, hemos discutido diferentes algoritmos de limitación de velocidad y sus
pros/contras. Los algoritmos discutidos incluyen:

- Token bucket
  
- Cubo de fuga
  
- Ventana fija
  
- Ventana deslizante de registro
  
- Contador de ventana móvil
  
A continuación, analizamos la arquitectura del sistema, el limitador de velocidad en un entorno distribuido, la optimización del rendimiento y la supervisión. Como en cualquier
pregunta de la entrevista de diseño de sistemas, hay puntos de conversación adicionales que puedes tocar si el tiempo lo permite:

- Limitación de velocidad dura frente a suave.
  
- Duro: el número de solicitudes no puede superar el umbral.
  
- Suave: las solicitudes pueden superar el umbral durante un breve periodo de tiempo.
  
- Limitación de velocidad a diferentes niveles. En este capítulo, sólo hemos hablado de
en el nivel de aplicación (HTTP: capa 7). Es posible aplicar
en otras capas. Por ejemplo, puede aplicar limitación de velocidad por direcciones IP utilizando Iptables [15](IP: capa 3). Nota: El modelo Open Systems
Interconexión de Sistemas Abiertos (modelo OSI) tiene 7 capas [16]: Capa 1: capa física
física, Capa 2: Capa de enlace de datos, Capa 3: Capa de red, Capa 4: Capa de transporte, Capa 5: Capa de sesión, Capa 6: Capa de Presentación, Capa 7: Capa de Aplicación:
Capa de aplicación.

- Evite las limitaciones de velocidad. Diseñe su cliente con las mejores prácticas:
  
- Utilice la caché del cliente para evitar hacer frecuentes llamadas a la API.
  
- Entender el límite y no enviar demasiadas peticiones en un corto espacio de tiempo.
corto.

- Incluya código para capturar excepciones o errores para que su cliente pueda recuperarse
recuperarse de las excepciones.

- Añade suficiente tiempo de recuperación para reintentar la lógica.
  
Enhorabuena por haber llegado hasta aquí. Ahora date una palmadita en la espalda.
Buen trabajo!!.

Materiales de referencia

[1] Estrategias y técnicas de limitación de velocidad:

https://cloud.google.com/solutions/rate-limiting-strategies-techniques

[2] Límites de velocidad en Twitter: 

https://developer.twitter.com/en/docs/basics/ratelimits

[3] Límites de uso de Google Docs: https://developers.google.com/docs/api/limits

[4] Microservicios de IBM: https://www.ibm.com/cloud/learn/microservices

[5] Acelerar las peticiones API para mejorar el rendimiento:

https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-request-throttling.html

[6] Limitadores de tarifa de Stripe: https://stripe.com/blog/rate-limiters

[7] Límites de tasa de la API REST Admin de Shopify:

https://help.shopify.com/en/api/reference/rest-admin-api-rate-limits

[8] Mejor limitación de velocidad con Redis Sorted Sets:

https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/

[9] Diseño del sistema - Limitador de tarifa y modelado de datos:

https://medium.com/@saisandeepmopuri/system-design-rate-limiter-anddata-modelling-9304b0d18250

[10] Cómo creamos un limitador de velocidad capaz de escalar a millones de dominios:

https://blog.cloudflare.com/counting-things-a-lot-of-different-things/

[11] Sitio web de Redis: https://redis.io/

[12] Limitación de velocidad de Lyft: https://github.com/lyft/ratelimit

[13] Cómo escalar tu API con limitadores de tasa:

https://gist.github.com/ptarjan/e38f45f2dfe601419ca3af937fff574d#request
-limitador de velocidad

[14] Qué es edge computing:

https://www.cloudflare.com/learning/serverless/glossary/what-is-edgecomputing/

[15] Limitación de velocidad de solicitudes con Iptables: 

https://blog.programster.org/ratelimit-requests-with-iptables

[16] Modelo OSI:

https://en.wikipedia.org/wiki/OSI_model#Layer_architecture
